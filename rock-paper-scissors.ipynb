{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressed-amino",
   "metadata": {},
   "source": [
    "# Rock Paper Scissors Image Classification - Final Submission Dicoding Indonesia\n",
    "### Course : Belajar Machine Learning Pemula\n",
    "### Date : 24 April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-abraham",
   "metadata": {},
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform image into array\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "\n",
    "# transform single image into array for prediction\n",
    "def single_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dan preprocess training data\n",
    "def train_data(train_data_path):\n",
    "    print(\"\\n-- PREPARE TRAINING DATA --\")\n",
    "    train_image = []\n",
    "    train_label = []\n",
    "\n",
    "    list_training = list(os.listdir(train_data_path))\n",
    "    label_size = len(list_training)\n",
    "\n",
    "    # CARA 2\n",
    "    # load image from each subject\n",
    "    sub_num = 0\n",
    "    for sub in (sorted(list_training)):\n",
    "        for photo in tqdm(os.listdir(f\"{train_data_path}/{sub}\"), desc=f\"{sub}\"):\n",
    "            if photo.endswith(\".jpg\"):\n",
    "                filename = f\"{train_data_path}/{sub}/{photo}\"\n",
    "                image_out = preprocess_image(filename)\n",
    "\n",
    "                # iamge feature and class in binary\n",
    "                train_image.append(image_out)\n",
    "                train_label.append(sub)\n",
    "        if(sub_num == 0):\n",
    "            np_train = np.array(train_image)\n",
    "        else:\n",
    "            np_train = np.concatenate((np_train, np.array(train_image)))\n",
    "        train_image.clear()\n",
    "        sub_num += 1\n",
    "\n",
    "    # encode train label\n",
    "    le_train = LabelEncoder()\n",
    "    train_label = le_train.fit_transform(train_label)\n",
    "    train_label = to_categorical(train_label, label_size)\n",
    "\n",
    "    # split data\n",
    "    X_train = np_train\n",
    "    y_train = train_label\n",
    "\n",
    "    return (X_train, y_train, le_train)\n",
    "\n",
    "\n",
    "# read dan preprocess testing data\n",
    "def test_data(test_data_path):\n",
    "    print(\"\\n-- PREPARE TESTING DATA --\")\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "\n",
    "    list_testing = list(os.listdir(test_data_path))\n",
    "    label_size = len(list_testing)\n",
    "\n",
    "    # CARA 2\n",
    "    # load image from each subject\n",
    "    sub_num = 0\n",
    "    for sub in (sorted(list_testing)):\n",
    "        for photo in tqdm(os.listdir(f\"{test_data_path}/{sub}\"), desc=f\"{sub}\"):\n",
    "            if photo.endswith(\".jpg\"):\n",
    "                filename = f\"{test_data_path}/{sub}/{photo}\"\n",
    "                image_out = preprocess_image(filename)\n",
    "\n",
    "                # iamge feature and class in binary\n",
    "                test_image.append(image_out)\n",
    "                test_label.append(sub)\n",
    "        if(sub_num == 0):\n",
    "            np_test = np.array(test_image)\n",
    "        else:\n",
    "            np_test = np.concatenate((np_test, np.array(test_image)))\n",
    "        test_image.clear()\n",
    "        sub_num += 1\n",
    "\n",
    "    # Encode test label\n",
    "    le_test = LabelEncoder()\n",
    "    test_label = le_test.fit_transform(test_label)\n",
    "    test_label = to_categorical(test_label, label_size)\n",
    "\n",
    "    # split data\n",
    "    X_test = np_test\n",
    "    y_test = test_label\n",
    "\n",
    "    return (X_test, y_test, le_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Constant\n",
    "BS = 20\n",
    "EPOCHS = 150\n",
    "MODEL_NAME = \"RESNET50\"\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"[INFO] Hyperparameter:\")\n",
    "print(\"Epoch: \" + str(EPOCHS))\n",
    "print(\"Learning rate: \" + str(LEARNING_RATE))\n",
    "print(\"Batch Size: \" + str(BS))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of train and test dataset\n",
    "training_dataset = f\"../Dataset/facescrub-crop-mtcnn-training\"\n",
    "list_training = list(os.listdir(training_dataset))\n",
    "testing_dataset = f\"../Dataset/facescrub-crop-mtcnn-testing\"\n",
    "list_testing = list(os.listdir(testing_dataset))\n",
    "\n",
    "label_size = len(list_training)\n",
    "image_per_label = len(os.listdir(f\"{training_dataset}/{list_training[0]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ TRAIN AND TEST DATA\n",
    "X_train, y_train, le_train = train_data(training_dataset)\n",
    "X_test, y_test, le_test = test_data(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-snowboard",
   "metadata": {},
   "source": [
    "## Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL\n",
    "model = resnet50(label_size)\n",
    "\n",
    "# SUMMARY MODEL\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE MODEL\n",
    "adam = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Callbacks\n",
    "my_callbacks = my_callbacks(MODEL_NAME, label_size,\n",
    "                            image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate start time\n",
    "start_time = time.time()\n",
    "\n",
    "# TRAIN MODEL\n",
    "Historia = model.fit(\n",
    "    aug.flow(X_train, y_train, batch_size=BS),\n",
    "    # X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=my_callbacks,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BS)\n",
    "\n",
    "# end time\n",
    "print(\"\\n\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-poison",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "model = load_my_model(MODEL_NAME, label_size, image_per_label, EPOCHS, BS)\n",
    "\n",
    "results = model.evaluate(X_test, y_test, batch_size=BS)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction for testing data\n",
    "predictions = [np.argmax(x) for x in model.predict(X_test, batch_size=BS)]\n",
    "tes = [np.argmax(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print_class_reports(tes, predictions, le_test.classes_, MODEL_NAME,\n",
    "                    label_size, image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "print_conf_matrix(tes, predictions, le_test.classes_, MODEL_NAME,\n",
    "                  label_size, image_per_label, EPOCHS, BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-semiconductor",
   "metadata": {},
   "source": [
    "## Observe Model Performance using Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "visualize_accuracy(Historia, MODEL_NAME,\n",
    "                   label_size, image_per_label, EPOCHS, BS)\n",
    "# loss\n",
    "visualize_loss(Historia, MODEL_NAME,\n",
    "               label_size, image_per_label, EPOCHS, BS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
